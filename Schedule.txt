目标： 做长文本作家文体风格分析
输入文章，输出可能的作家
（一大堆引用）

应用：作品风格借鉴和相似度检测、文学风格研究、文本作者身份识别（鲁迅为例）
“你的文章风格像谁？”

1. 数据清洗
用notepad++ convert to utf-8再用python读入
用notepad清洗了广告...
Python数据清洗完成（包括清洗广告和章节开头）
注释和无关章节需要人工处理

2. 特征提取
先分句――找句号、叹号、问号、冒号、分号、省略号切开，插入\n

再分词――FudanNLP貌似效果不好，考虑jieba

词汇特征：
jieba关键词提取（基于TFIDF）――与主题相关，不能用
词汇丰富度
标注词性后使用词频，可以求出各个词性的前几个最高频词
词性特征：
	词性标注使用jieba

标点特征：各种标点出现次数

句法特征：
	虚词（功能词）包括介词p、（并列、从属）连词c、叹词e、结构助词u、语气词y、方位词f

依存句法特征：FudanNLP 输入一个句子，输出依赖树，包括22种依赖关系和若干种（42）词性
完成
用每一句的依赖关系代表这一句的结构

语义特征：与主题相关，不能用

复合特征：
各种东西除一下

3. 分类：作者识别
大样本建立作家风格数据库（随时可以运行）
降维？
新样本测试准确率
设计比对算法：加权距离度量
数据可视化――句法依存的概率分布图、词云、直方图等等
规范储存方式，每行一个数据


4. 问题与改善
怎么调java是个大问题？已解决
先不管这个（考虑到没必要多次重启python解析器，应该用Python来循环读取文件，然后batch调用。）


怎样利用段落特征？
怎样利用句间特征？


baidu api调用：当且仅当text的值为GBK时有回应，但是回应的是GBK编码串的答案。。。